{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7e749c",
   "metadata": {},
   "source": [
    "> #### Load the initial AGN catalogue and untar it which is given here : https://data.galaxyzoo.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8221a13",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'schawinski_GZ_2010_catalogue.fits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschawinski_GZ_2010_catalogue.fits.gz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_in:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mschawinski_GZ_2010_catalogue.fits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f_out:\n\u001b[0;32m      6\u001b[0m         shutil\u001b[38;5;241m.\u001b[39mcopyfileobj(f_in, f_out)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'schawinski_GZ_2010_catalogue.fits'"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "with gzip.open('schawinski_GZ_2010_catalogue.fits.gz', 'rb') as f_in:\n",
    "    with open('schawinski_GZ_2010_catalogue.fits', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2656d3",
   "metadata": {},
   "source": [
    "> #### Look at the fits file structure to identify needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecdd7f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: schawinski_GZ_2010_catalogue.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1                1 BinTableHDU     51   1R x 15C   [858150A, 47675D, 47675D, 47675D, 47675J, 47675J, 47675E, 47675E, 47675E, 47675E, 47675E, 47675E, 47675E, 47675E, 47675D]   \n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "hdul = fits.open('schawinski_GZ_2010_catalogue.fits')\n",
    "hdul.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97f3a7",
   "metadata": {},
   "source": [
    "> #### Print dataframe info in a better manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ab0d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 15\n",
      "\n",
      "Detailed column info:\n",
      "\n",
      "ColDefs(\n",
      "    name = 'OBJID'; format = '858150A'; dim = '(18, 47675)'\n",
      "    name = 'RA'; format = '47675D'\n",
      "    name = 'DEC'; format = '47675D'\n",
      "    name = 'REDSHIFT'; format = '47675D'\n",
      "    name = 'GZ1_MORPHOLOGY'; format = '47675J'\n",
      "    name = 'BPT_CLASS'; format = '47675J'\n",
      "    name = 'U'; format = '47675E'\n",
      "    name = 'G'; format = '47675E'\n",
      "    name = 'R'; format = '47675E'\n",
      "    name = 'I'; format = '47675E'\n",
      "    name = 'Z'; format = '47675E'\n",
      "    name = 'SIGMA'; format = '47675E'\n",
      "    name = 'SIGMA_ERR'; format = '47675E'\n",
      "    name = 'LOG_MSTELLAR'; format = '47675E'\n",
      "    name = 'L_O3'; format = '47675D'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "# Open FITS file\n",
    "hdul = fits.open(\"data/schawinski_GZ_2010_catalogue.fits\")\n",
    "\n",
    "# Access the binary table HDU\n",
    "hdu = hdul[1]\n",
    "\n",
    "# Print a structured summary of columns\n",
    "print(\"Number of columns:\", len(hdu.columns))\n",
    "print(\"\\nDetailed column info:\\n\")\n",
    "print(hdu.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b762a17b",
   "metadata": {},
   "source": [
    "> #### Convert the fits file to a CSV for easier handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da190bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load AGN sample\n",
    "print(\"Loading Schawinski GZ 2010 catalogue...\")\n",
    "with fits.open('schawinski_GZ_2010_catalogue.fits') as hdul_agn:\n",
    "    agn_data = hdul_agn[1].data\n",
    "\n",
    "# Each column is an array stored inside one record\n",
    "agn_cols = agn_data.columns.names or agn_data.names\n",
    "print(f\"Columns: {agn_cols}\")\n",
    "\n",
    "# Extract the arrays from the first (and only) record\n",
    "agn_dict = {col: np.array(agn_data[0][col]) for col in agn_cols}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_agn = pd.DataFrame(agn_dict)\n",
    "print(f\"Expanded AGN sample shape: {df_agn.shape}\")\n",
    "print(df_agn.head())\n",
    "\n",
    "print(df_agn.info())\n",
    "\n",
    "df_agn.to_csv(\"schawinski_GZ2010_AGN_catalogue.csv\", index=False)\n",
    "print(\"✅ AGN catalogue saved to 'schawinski_GZ2010_AGN_catalogue.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c38313e",
   "metadata": {},
   "source": [
    "> #### Unzip the Galaxy Zoo 2 Table 1 information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcdfc930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "with gzip.open('gz2_hart16.csv.gz', 'rb') as f_in:\n",
    "    with open('gz2_hart16.csv', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad6379",
   "metadata": {},
   "source": [
    "> #### Now crossmatch the SDSS DR7 object ids for galaxies with the AGN catalogue to extend the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ed72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AGN catalogue...\n",
      "Loading GZ2 Hart catalogue...\n",
      "Performing unique inner join on string IDs...\n",
      "✅ Unique matched catalogue saved to 'AGN_GZ2_Hart_DR7_final.csv'\n",
      "Matched sample size: 44361\n",
      "Match rate: 93.05% of unique AGN sample\n",
      "\n",
      "Matched dataset columns:\n",
      "['OBJID', 'RA', 'DEC', 'REDSHIFT', 'GZ1_MORPHOLOGY', 'BPT_CLASS', 'U', 'G', 'R', 'I', 'Z', 'SIGMA', 'SIGMA_ERR', 'LOG_MSTELLAR', 'L_O3', 'dr7objid', 'ra', 'dec', 'rastring', 'decstring', 'sample', 'gz2_class', 'total_classifications', 'total_votes', 't01_smooth_or_features_a01_smooth_count', 't01_smooth_or_features_a01_smooth_weight', 't01_smooth_or_features_a01_smooth_fraction', 't01_smooth_or_features_a01_smooth_weighted_fraction', 't01_smooth_or_features_a01_smooth_debiased', 't01_smooth_or_features_a01_smooth_flag', 't01_smooth_or_features_a02_features_or_disk_count', 't01_smooth_or_features_a02_features_or_disk_weight', 't01_smooth_or_features_a02_features_or_disk_fraction', 't01_smooth_or_features_a02_features_or_disk_weighted_fraction', 't01_smooth_or_features_a02_features_or_disk_debiased', 't01_smooth_or_features_a02_features_or_disk_flag', 't01_smooth_or_features_a03_star_or_artifact_count', 't01_smooth_or_features_a03_star_or_artifact_weight', 't01_smooth_or_features_a03_star_or_artifact_fraction', 't01_smooth_or_features_a03_star_or_artifact_weighted_fraction', 't01_smooth_or_features_a03_star_or_artifact_debiased', 't01_smooth_or_features_a03_star_or_artifact_flag', 't02_edgeon_a04_yes_count', 't02_edgeon_a04_yes_weight', 't02_edgeon_a04_yes_fraction', 't02_edgeon_a04_yes_weighted_fraction', 't02_edgeon_a04_yes_debiased', 't02_edgeon_a04_yes_flag', 't02_edgeon_a05_no_count', 't02_edgeon_a05_no_weight', 't02_edgeon_a05_no_fraction', 't02_edgeon_a05_no_weighted_fraction', 't02_edgeon_a05_no_debiased', 't02_edgeon_a05_no_flag', 't03_bar_a06_bar_count', 't03_bar_a06_bar_weight', 't03_bar_a06_bar_fraction', 't03_bar_a06_bar_weighted_fraction', 't03_bar_a06_bar_debiased', 't03_bar_a06_bar_flag', 't03_bar_a07_no_bar_count', 't03_bar_a07_no_bar_weight', 't03_bar_a07_no_bar_fraction', 't03_bar_a07_no_bar_weighted_fraction', 't03_bar_a07_no_bar_debiased', 't03_bar_a07_no_bar_flag', 't04_spiral_a08_spiral_count', 't04_spiral_a08_spiral_weight', 't04_spiral_a08_spiral_fraction', 't04_spiral_a08_spiral_weighted_fraction', 't04_spiral_a08_spiral_debiased', 't04_spiral_a08_spiral_flag', 't04_spiral_a09_no_spiral_count', 't04_spiral_a09_no_spiral_weight', 't04_spiral_a09_no_spiral_fraction', 't04_spiral_a09_no_spiral_weighted_fraction', 't04_spiral_a09_no_spiral_debiased', 't04_spiral_a09_no_spiral_flag', 't05_bulge_prominence_a10_no_bulge_count', 't05_bulge_prominence_a10_no_bulge_weight', 't05_bulge_prominence_a10_no_bulge_fraction', 't05_bulge_prominence_a10_no_bulge_weighted_fraction', 't05_bulge_prominence_a10_no_bulge_debiased', 't05_bulge_prominence_a10_no_bulge_flag', 't05_bulge_prominence_a11_just_noticeable_count', 't05_bulge_prominence_a11_just_noticeable_weight', 't05_bulge_prominence_a11_just_noticeable_fraction', 't05_bulge_prominence_a11_just_noticeable_weighted_fraction', 't05_bulge_prominence_a11_just_noticeable_debiased', 't05_bulge_prominence_a11_just_noticeable_flag', 't05_bulge_prominence_a12_obvious_count', 't05_bulge_prominence_a12_obvious_weight', 't05_bulge_prominence_a12_obvious_fraction', 't05_bulge_prominence_a12_obvious_weighted_fraction', 't05_bulge_prominence_a12_obvious_debiased', 't05_bulge_prominence_a12_obvious_flag', 't05_bulge_prominence_a13_dominant_count', 't05_bulge_prominence_a13_dominant_weight', 't05_bulge_prominence_a13_dominant_fraction', 't05_bulge_prominence_a13_dominant_weighted_fraction', 't05_bulge_prominence_a13_dominant_debiased', 't05_bulge_prominence_a13_dominant_flag', 't06_odd_a14_yes_count', 't06_odd_a14_yes_weight', 't06_odd_a14_yes_fraction', 't06_odd_a14_yes_weighted_fraction', 't06_odd_a14_yes_debiased', 't06_odd_a14_yes_flag', 't06_odd_a15_no_count', 't06_odd_a15_no_weight', 't06_odd_a15_no_fraction', 't06_odd_a15_no_weighted_fraction', 't06_odd_a15_no_debiased', 't06_odd_a15_no_flag', 't07_rounded_a16_completely_round_count', 't07_rounded_a16_completely_round_weight', 't07_rounded_a16_completely_round_fraction', 't07_rounded_a16_completely_round_weighted_fraction', 't07_rounded_a16_completely_round_debiased', 't07_rounded_a16_completely_round_flag', 't07_rounded_a17_in_between_count', 't07_rounded_a17_in_between_weight', 't07_rounded_a17_in_between_fraction', 't07_rounded_a17_in_between_weighted_fraction', 't07_rounded_a17_in_between_debiased', 't07_rounded_a17_in_between_flag', 't07_rounded_a18_cigar_shaped_count', 't07_rounded_a18_cigar_shaped_weight', 't07_rounded_a18_cigar_shaped_fraction', 't07_rounded_a18_cigar_shaped_weighted_fraction', 't07_rounded_a18_cigar_shaped_debiased', 't07_rounded_a18_cigar_shaped_flag', 't08_odd_feature_a19_ring_count', 't08_odd_feature_a19_ring_weight', 't08_odd_feature_a19_ring_fraction', 't08_odd_feature_a19_ring_weighted_fraction', 't08_odd_feature_a19_ring_debiased', 't08_odd_feature_a19_ring_flag', 't08_odd_feature_a20_lens_or_arc_count', 't08_odd_feature_a20_lens_or_arc_weight', 't08_odd_feature_a20_lens_or_arc_fraction', 't08_odd_feature_a20_lens_or_arc_weighted_fraction', 't08_odd_feature_a20_lens_or_arc_debiased', 't08_odd_feature_a20_lens_or_arc_flag', 't08_odd_feature_a21_disturbed_count', 't08_odd_feature_a21_disturbed_weight', 't08_odd_feature_a21_disturbed_fraction', 't08_odd_feature_a21_disturbed_weighted_fraction', 't08_odd_feature_a21_disturbed_debiased', 't08_odd_feature_a21_disturbed_flag', 't08_odd_feature_a22_irregular_count', 't08_odd_feature_a22_irregular_weight', 't08_odd_feature_a22_irregular_fraction', 't08_odd_feature_a22_irregular_weighted_fraction', 't08_odd_feature_a22_irregular_debiased', 't08_odd_feature_a22_irregular_flag', 't08_odd_feature_a23_other_count', 't08_odd_feature_a23_other_weight', 't08_odd_feature_a23_other_fraction', 't08_odd_feature_a23_other_weighted_fraction', 't08_odd_feature_a23_other_debiased', 't08_odd_feature_a23_other_flag', 't08_odd_feature_a24_merger_count', 't08_odd_feature_a24_merger_weight', 't08_odd_feature_a24_merger_fraction', 't08_odd_feature_a24_merger_weighted_fraction', 't08_odd_feature_a24_merger_debiased', 't08_odd_feature_a24_merger_flag', 't08_odd_feature_a38_dust_lane_count', 't08_odd_feature_a38_dust_lane_weight', 't08_odd_feature_a38_dust_lane_fraction', 't08_odd_feature_a38_dust_lane_weighted_fraction', 't08_odd_feature_a38_dust_lane_debiased', 't08_odd_feature_a38_dust_lane_flag', 't09_bulge_shape_a25_rounded_count', 't09_bulge_shape_a25_rounded_weight', 't09_bulge_shape_a25_rounded_fraction', 't09_bulge_shape_a25_rounded_weighted_fraction', 't09_bulge_shape_a25_rounded_debiased', 't09_bulge_shape_a25_rounded_flag', 't09_bulge_shape_a26_boxy_count', 't09_bulge_shape_a26_boxy_weight', 't09_bulge_shape_a26_boxy_fraction', 't09_bulge_shape_a26_boxy_weighted_fraction', 't09_bulge_shape_a26_boxy_debiased', 't09_bulge_shape_a26_boxy_flag', 't09_bulge_shape_a27_no_bulge_count', 't09_bulge_shape_a27_no_bulge_weight', 't09_bulge_shape_a27_no_bulge_fraction', 't09_bulge_shape_a27_no_bulge_weighted_fraction', 't09_bulge_shape_a27_no_bulge_debiased', 't09_bulge_shape_a27_no_bulge_flag', 't10_arms_winding_a28_tight_count', 't10_arms_winding_a28_tight_weight', 't10_arms_winding_a28_tight_fraction', 't10_arms_winding_a28_tight_weighted_fraction', 't10_arms_winding_a28_tight_debiased', 't10_arms_winding_a28_tight_flag', 't10_arms_winding_a29_medium_count', 't10_arms_winding_a29_medium_weight', 't10_arms_winding_a29_medium_fraction', 't10_arms_winding_a29_medium_weighted_fraction', 't10_arms_winding_a29_medium_debiased', 't10_arms_winding_a29_medium_flag', 't10_arms_winding_a30_loose_count', 't10_arms_winding_a30_loose_weight', 't10_arms_winding_a30_loose_fraction', 't10_arms_winding_a30_loose_weighted_fraction', 't10_arms_winding_a30_loose_debiased', 't10_arms_winding_a30_loose_flag', 't11_arms_number_a31_1_count', 't11_arms_number_a31_1_weight', 't11_arms_number_a31_1_fraction', 't11_arms_number_a31_1_weighted_fraction', 't11_arms_number_a31_1_debiased', 't11_arms_number_a31_1_flag', 't11_arms_number_a32_2_count', 't11_arms_number_a32_2_weight', 't11_arms_number_a32_2_fraction', 't11_arms_number_a32_2_weighted_fraction', 't11_arms_number_a32_2_debiased', 't11_arms_number_a32_2_flag', 't11_arms_number_a33_3_count', 't11_arms_number_a33_3_weight', 't11_arms_number_a33_3_fraction', 't11_arms_number_a33_3_weighted_fraction', 't11_arms_number_a33_3_debiased', 't11_arms_number_a33_3_flag', 't11_arms_number_a34_4_count', 't11_arms_number_a34_4_weight', 't11_arms_number_a34_4_fraction', 't11_arms_number_a34_4_weighted_fraction', 't11_arms_number_a34_4_debiased', 't11_arms_number_a34_4_flag', 't11_arms_number_a36_more_than_4_count', 't11_arms_number_a36_more_than_4_weight', 't11_arms_number_a36_more_than_4_fraction', 't11_arms_number_a36_more_than_4_weighted_fraction', 't11_arms_number_a36_more_than_4_debiased', 't11_arms_number_a36_more_than_4_flag', 't11_arms_number_a37_cant_tell_count', 't11_arms_number_a37_cant_tell_weight', 't11_arms_number_a37_cant_tell_fraction', 't11_arms_number_a37_cant_tell_weighted_fraction', 't11_arms_number_a37_cant_tell_debiased', 't11_arms_number_a37_cant_tell_flag']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Loading AGN catalogue...\")\n",
    "# --- FIX: Read OBJID as a string to prevent precision loss ---\n",
    "df_agn = pd.read_csv(\n",
    "    \"schawinski_GZ2010_AGN_catalogue.csv\",\n",
    "    dtype={'OBJID': str}\n",
    ")\n",
    "\n",
    "print(\"Loading GZ2 Hart catalogue...\")\n",
    "# --- FIX: Read dr7objid as a string to prevent precision loss ---\n",
    "df_gz2 = pd.read_csv(\n",
    "    \"gz2_hart16.csv\",\n",
    "    dtype={'dr7objid': str}\n",
    ")\n",
    "\n",
    "# --- Drop any missing values in join columns ---\n",
    "df_agn = df_agn.dropna(subset=['OBJID'])\n",
    "df_gz2 = df_gz2.dropna(subset=['dr7objid'])\n",
    "\n",
    "# --- No longer need astype(int) ---\n",
    "# The IDs are now strings and will merge correctly.\n",
    "\n",
    "# --- Remove duplicates before merging ---\n",
    "df_agn_unique = df_agn.drop_duplicates(subset='OBJID')\n",
    "df_gz2_unique = df_gz2.drop_duplicates(subset='dr7objid')\n",
    "\n",
    "print(\"Performing unique inner join on string IDs...\")\n",
    "# --- Perform the inner join ---\n",
    "df_matched_unique = pd.merge(\n",
    "    df_agn_unique,\n",
    "    df_gz2_unique,\n",
    "    left_on='OBJID',\n",
    "    right_on='dr7objid',\n",
    "    how='inner',\n",
    "    suffixes=('_agn', '_gz2')\n",
    ")\n",
    "\n",
    "# --- Save the unique matched catalogue ---\n",
    "output_file = \"AGN_GZ2_Hart_DR7_final.csv\"\n",
    "df_matched_unique.to_csv(output_file, index=False)\n",
    "\n",
    "# --- Print summary ---\n",
    "print(f\"✅ Unique matched catalogue saved to '{output_file}'\")\n",
    "print(f\"Matched sample size: {len(df_matched_unique)}\")\n",
    "if len(df_agn_unique) > 0:\n",
    "    match_rate = len(df_matched_unique) / len(df_agn_unique) * 100\n",
    "    print(f\"Match rate: {match_rate:.2f}% of unique AGN sample\")\n",
    "else:\n",
    "    print(\"No unique AGN samples found to calculate match rate.\")\n",
    "print(\"\\nMatched dataset columns:\")\n",
    "print(df_matched_unique.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2ad6f6",
   "metadata": {},
   "source": [
    "> #### Extract the images for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "370fa3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to images_gz2\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to your zip file\n",
    "zip_path = \"data/images_gz2.zip\"\n",
    "\n",
    "# Directory where you want to extract files\n",
    "extract_dir = \"images_gz2\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# Open and extract all contents\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(f\"Files extracted to {extract_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6ba6d8",
   "metadata": {},
   "source": [
    "> #### Updated code for creating the labels in a json format verifying with the available images  along with adding new lables for `star_forming`, `has_agn`, and `mass` for the galaxy zoo 2 dataset crossmatched with the AGN catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b3e304a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading votes data from: data/AGN_GZ2_Hart_DR7_final.csv\n",
      "Loading map data from: data/gz2_filename_mapping.csv\n",
      "Using 'dr7objid' from votes file as join key (correct for GZ2 mapping).\n",
      "Votes file: Found 44361 valid rows with key 'dr7objid'.\n",
      "Map file: Found 355990 valid rows with key 'objid'.\n",
      "Loaded 44361 merged rows.\n",
      "Classifying galaxies (GZ2)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████| 44361/44361 [00:04<00:00, 9266.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating new labels (BPT, Mass)...\n",
      "Finding image paths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Images: 100%|██████████| 44361/44361 [00:01<00:00, 22620.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GZ2 Classification Counts (Valid) ---\n",
      "classification\n",
      "spiral        5848\n",
      "elliptical     353\n",
      "irregular      215\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- New Label Counts (Valid) ---\n",
      "Star Forming: 2755\n",
      "Has AGN:      353\n",
      "Galaxies w/ Mass crossmatched with images: 6416\n",
      "✅ Saved 6416 galaxies to data/labels_master.json\n",
      "\n",
      "Selecting top-N per class...\n",
      "\n",
      "--- Top-N GZ2 Classification Counts ---\n",
      "classification\n",
      "spiral        2000\n",
      "elliptical     353\n",
      "irregular      215\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Top-N New Label Counts ---\n",
      "Star Forming: 1030\n",
      "Has AGN:      146\n",
      "Galaxies w/ Mass crossmatched with images: 2568\n",
      "✅ Saved 2568 galaxies to data/labels_master_top_n.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "# *** ASSUMPTION ***:\n",
    "# This script assumes VOTES_CSV now points to your new, merged file\n",
    "# that contains both the GZ2 vote columns AND the new label columns\n",
    "# (BPT_CLASS, LOG_MSTELLAR, etc.)\n",
    "VOTES_CSV = \"data/AGN_GZ2_Hart_DR7_final.csv\" # <-- Make sure this is your new file path\n",
    "MAP_CSV = \"data/gz2_filename_mapping.csv\" # <-- Make sure this is your map file path\n",
    "IMG_DIR = \"data/images_gz2/images\" # <-- Make sure this path is correct\n",
    "OUT_JSON_ALL = \"data/labels_master.json\"\n",
    "OUT_JSON_TOP = \"data/labels_master_top_n.json\"\n",
    "\n",
    "# --- THRESHOLDS ---\n",
    "THRESHOLDS = {\n",
    "    'artifact': 0.2,\n",
    "    'elliptical': 0.95,\n",
    "    'nospiral': 0.9,\n",
    "    'spiral': 0.95,\n",
    "    'features': 0.9,\n",
    "    'edgeon_ell': 0.1,\n",
    "    'edgeon_spiral': 0.2,\n",
    "    'odd': 0.7,\n",
    "    'irregular': 0.7\n",
    "}\n",
    "\n",
    "def load_data(votes_csv, map_csv):\n",
    "    \"\"\"\n",
    "    Load and merge the Galaxy Zoo vote fractions (now with new labels)\n",
    "    and the filename mapping.\n",
    "    Returns a merged DataFrame with consistent 'objid' type.\n",
    "    \"\"\"\n",
    "    print(f\"Loading votes data from: {votes_csv}\")\n",
    "    try:\n",
    "        votes_df = pd.read_csv(votes_csv, low_memory=False)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"CRITICAL ERROR: Votes file not found at {votes_csv}\")\n",
    "        return pd.DataFrame() # Return empty DF\n",
    "\n",
    "    print(f\"Loading map data from: {map_csv}\")\n",
    "    try:\n",
    "        map_df = pd.read_csv(map_csv, low_memory=False)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"CRITICAL ERROR: Map file not found at {map_csv}\")\n",
    "        return pd.DataFrame() # Return empty DF\n",
    "\n",
    "    # --- UPDATED JOIN LOGIC ---\n",
    "    # We must join with the GZ2 filename mapping file using the GZ2 ID,\n",
    "    # which is 'dr7objid'. This is the correct key.\n",
    "    join_key_name = None\n",
    "    if \"dr7objid\" in votes_df.columns:\n",
    "        print(\"Using 'dr7objid' from votes file as join key (correct for GZ2 mapping).\")\n",
    "        votes_df = votes_df.rename(columns={\"dr7objid\": \"objid_to_join\"})\n",
    "        join_key_name = \"dr7objid\"\n",
    "    elif \"OBJID\" in votes_df.columns:\n",
    "        print(\"Warning: 'dr7objid' not found. Falling back to 'OBJID'. This may result in 0 merges.\")\n",
    "        votes_df = votes_df.rename(columns={\"OBJID\": \"objid_to_join\"})\n",
    "        join_key_name = \"OBJID\"\n",
    "    else:\n",
    "        print(\"CRITICAL ERROR: Could not find 'dr7objid' or 'OBJID' in votes CSV.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Check the map file for its 'objid'\n",
    "    if \"objid\" not in map_df.columns:\n",
    "        print(\"CRITICAL ERROR: Could not find 'objid' column in map CSV.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    map_df = map_df.rename(columns={\"objid\": \"objid_to_join\"})\n",
    "    # --- END UPDATED JOIN LOGIC ---\n",
    "\n",
    "    # Ensure merge keys are the same integer type\n",
    "    votes_df['objid_to_join'] = pd.to_numeric(votes_df['objid_to_join'], errors='coerce').astype('Int64')\n",
    "    map_df['objid_to_join'] = pd.to_numeric(map_df['objid_to_join'], errors='coerce').astype('Int64')\n",
    "    \n",
    "    # Drop rows where objid became NaT\n",
    "    votes_df = votes_df.dropna(subset=['objid_to_join'])\n",
    "    map_df = map_df.dropna(subset=['objid_to_join'])\n",
    "\n",
    "    print(f\"Votes file: Found {len(votes_df)} valid rows with key '{join_key_name}'.\")\n",
    "    print(f\"Map file: Found {len(map_df)} valid rows with key 'objid'.\")\n",
    "\n",
    "    # Perform the merge\n",
    "    merged_df = votes_df.merge(map_df, on=\"objid_to_join\", how=\"inner\")\n",
    "    \n",
    "    # Rename the join key back to 'objid' for the rest of the script\n",
    "    # This script (and the original) uses 'objid' (from dr7objid) as the key\n",
    "    if 'objid_to_join' in merged_df.columns:\n",
    "         merged_df = merged_df.rename(columns={\"objid_to_join\": \"objid\"})\n",
    "\n",
    "    # The original script used 'dr7objid' and renamed it to 'objid'.\n",
    "    # We must ensure the column we use for finding image paths is\n",
    "    # named 'objid' in the final dataframe.\n",
    "    if \"objid\" not in merged_df.columns:\n",
    "        print(\"Warning: Final merge logic failed to produce 'objid' column.\")\n",
    "    \n",
    "    # The 'OBJID' (from AGN catalog) will just pass through if it was present\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "def classify_gz2(row):\n",
    "    \"\"\"\n",
    "    Classify a galaxy into elliptical, spiral, or irregular\n",
    "    using ultra-strict debiased vote fraction thresholds.\n",
    "    Returns (label, metrics_dict).\n",
    "    \"\"\"\n",
    "    # This function is unchanged, it only returns the GZ2 classification\n",
    "    # and the vote fraction metrics.\n",
    "    m = {\n",
    "        'artifact_prob': row['t01_smooth_or_features_a03_star_or_artifact_debiased'],\n",
    "        'smooth_prob': row['t01_smooth_or_features_a01_smooth_debiased'],\n",
    "        'features_prob': row['t01_smooth_or_features_a02_features_or_disk_debiased'],\n",
    "        'edgeon_prob': row['t02_edgeon_a04_yes_debiased'],\n",
    "        'spiral_prob': row['t04_spiral_a08_spiral_debiased'],\n",
    "        'nospiral_prob': row['t04_spiral_a09_no_spiral_debiased'],\n",
    "        'irregular_prob': row['t08_odd_feature_a22_irregular_debiased'],\n",
    "        'merger_prob': row['t08_odd_feature_a24_merger_debiased'],\n",
    "        'disturbed_prob': row['t08_odd_feature_a21_disturbed_debiased'],\n",
    "        'odd_prob': row['t06_odd_a14_yes_debiased']\n",
    "    }\n",
    "\n",
    "    if pd.isna(m['artifact_prob']):\n",
    "        # Handle rows with missing vote data\n",
    "        return None, m\n",
    "\n",
    "    if m['artifact_prob'] >= THRESHOLDS['artifact']:\n",
    "        return None, m\n",
    "\n",
    "    if (m['smooth_prob'] >= THRESHOLDS['elliptical'] and\n",
    "        m['edgeon_prob'] < THRESHOLDS['edgeon_ell'] and\n",
    "        m['nospiral_prob'] >= THRESHOLDS['nospiral']):\n",
    "        return \"elliptical\", m\n",
    "\n",
    "    if (m['spiral_prob'] >= THRESHOLDS['spiral'] and\n",
    "        m['features_prob'] >= THRESHOLDS['features'] and\n",
    "        m['edgeon_prob'] < THRESHOLDS['edgeon_spiral']):\n",
    "        return \"spiral\", m\n",
    "\n",
    "    if (m['odd_prob'] >= THRESHOLDS['odd'] and\n",
    "        max(m['irregular_prob'], m['merger_prob'], m['disturbed_prob']) >= THRESHOLDS['irregular']):\n",
    "        return \"irregular\", m\n",
    "\n",
    "    return None, m\n",
    "\n",
    "\n",
    "def find_image_path(asset_id):\n",
    "    \"\"\"\n",
    "    find the image path for a given asset_id\n",
    "    Returns the path if found, else None\n",
    "    \"\"\"\n",
    "    # This function is unchanged\n",
    "    patterns = [\n",
    "        f\"{asset_id}.jpg\",\n",
    "        # f\"{int(asset_id)}.jpg\"\n",
    "    ]\n",
    "    for pat in patterns:\n",
    "        p = os.path.join(IMG_DIR, pat)\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "\n",
    "def top_n(df, n_per_class):\n",
    "    \"\"\"\n",
    "    For each class, select the top N galaxies sorted by the strongest\n",
    "    confidence metric relevant to that class.\n",
    "    \"\"\"\n",
    "    # This function is unchanged\n",
    "    best_rows = []\n",
    "    for cls in ['elliptical', 'spiral', 'irregular']:\n",
    "        subset = df[df['classification'] == cls].copy()\n",
    "        if cls == 'elliptical':\n",
    "            subset['sort_value'] = subset['metrics'].apply(lambda x: x['smooth_prob'])\n",
    "        elif cls == 'spiral':\n",
    "            subset['sort_value'] = subset['metrics'].apply(lambda x: x['spiral_prob'])\n",
    "        elif cls == 'irregular':\n",
    "            subset['sort_value'] = subset['metrics'].apply(lambda x: max(\n",
    "                x.get('irregular_prob', 0), # use .get for safety\n",
    "                x.get('merger_prob', 0),\n",
    "                x.get('disturbed_prob', 0)\n",
    "            ) if x else 0)\n",
    "        subset = subset.sort_values(by='sort_value', ascending=False)\n",
    "        best_rows.append(subset.head(n_per_class))\n",
    "    return pd.concat(best_rows)\n",
    "\n",
    "\n",
    "def save_json(df, out_path):\n",
    "    \"\"\"\n",
    "    Save the DataFrame to JSON with:\n",
    "    - image path\n",
    "    - objid (this will be the dr7objid)\n",
    "    - classification\n",
    "    - metrics (vote fractions)\n",
    "    - NEW: star_forming, has_agn, mass\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    # Check if 'objid' is present after all merging\n",
    "    if 'objid' not in df.columns:\n",
    "        print(f\"CRITICAL ERROR: Cannot save JSON. 'objid' column is missing.\")\n",
    "        print(\"This likely means the data merging failed.\")\n",
    "        return\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # Handle potential NaNs for mass when converting to JSON\n",
    "        mass_val = row['mass']\n",
    "        if pd.isna(mass_val):\n",
    "            mass_val = None\n",
    "            \n",
    "        entry = {\n",
    "            \"image_path\": row['image_path'],\n",
    "            # 'objid' is the one we defined as the key (from dr7objid)\n",
    "            \"objid\": int(row['objid']), \n",
    "            \"classification\": row['classification'],\n",
    "            \"metrics\": row['metrics'],\n",
    "            # --- NEW LABELS ADDED ---\n",
    "            \"star_forming\": int(row['star_forming']), # Cast to 0 or 1\n",
    "            \"has_agn\": int(row['has_agn']),           # Cast to 0 or 1\n",
    "            \"mass\": mass_val\n",
    "        }\n",
    "        data.append(entry)\n",
    "\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"✅ Saved {len(data)} galaxies to {out_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_data(VOTES_CSV, MAP_CSV)\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Loaded DataFrame is empty. Halting execution.\")\n",
    "        print(\"Please check your file paths and merge keys (OBJID, dr7objid, objid).\")\n",
    "    else:\n",
    "        print(f\"Loaded {len(df)} merged rows.\")\n",
    "\n",
    "        print(\"Classifying galaxies (GZ2)...\")\n",
    "        tqdm.pandas(desc=\"Classifying\")\n",
    "        \n",
    "        # --- THIS IS THE FIX ---\n",
    "        # Using result_type='expand' is more robust than the lambda function,\n",
    "        # especially if the dataframe 'df' happens to be empty after loading.\n",
    "        # It correctly tells pandas to expand the 2-tuple returned by\n",
    "        # classify_gz2 into two new columns.\n",
    "        df[['classification', 'metrics']] = df.progress_apply(\n",
    "            classify_gz2, axis=1, result_type='expand'\n",
    "        )\n",
    "        # --- END FIX ---\n",
    "\n",
    "        # --- NEW: Add new labels ---\n",
    "        print(\"Calculating new labels (BPT, Mass)...\")\n",
    "        \n",
    "        # Check if columns exist before processing\n",
    "        if 'BPT_CLASS' not in df.columns:\n",
    "            print(\"Warning: 'BPT_CLASS' column not found. 'star_forming' and 'has_agn' will be 0.\")\n",
    "            df['BPT_CLASS'] = np.nan # Add empty column to avoid errors\n",
    "            \n",
    "        if 'LOG_MSTELLAR' not in df.columns:\n",
    "            print(\"Warning: 'LOG_MSTELLAR' column not found. 'mass' will be None.\")\n",
    "            df['LOG_MSTELLAR'] = np.nan # Add empty column to avoid errors\n",
    "\n",
    "        # 1. star_forming: 1 if BPT_CLASS is 1, else 0\n",
    "        # .apply is safer for NaNs (NaN == 1 is False)\n",
    "        df['star_forming'] = df['BPT_CLASS'].apply(lambda x: 1 if x == 1 else 0)\n",
    "        \n",
    "        # 2. has_agn: 1 if BPT_CLASS is 3 (Seyfert) or 4 (LINER), else 0\n",
    "        df['has_agn'] = df['BPT_CLASS'].apply(lambda x: 1 if x in [3, 4] else 0)\n",
    "        \n",
    "        # 3. mass: Convert LOG_MSTELLAR to normal mass (10^LOG_MSTELLAR)\n",
    "        # Use pd.notna to handle NaNs/Nones safely\n",
    "        df['mass'] = df['LOG_MSTELLAR'].apply(lambda x: np.power(10, x) if pd.notna(x) else None)\n",
    "        # --- END NEW ---\n",
    "\n",
    "        print(\"Finding image paths...\")\n",
    "        if 'asset_id' not in df.columns:\n",
    "            print(\"CRITICAL ERROR: 'asset_id' column not found in merged data.\")\n",
    "            print(\"This column is required from the 'gz2_filename_mapping.csv' file.\")\n",
    "        else:\n",
    "            tqdm.pandas(desc=\"Finding Images\")\n",
    "            df['image_path'] = df['asset_id'].progress_apply(find_image_path)\n",
    "\n",
    "            # Filter *after* all data is added\n",
    "            valid_df = df[df['classification'].notnull() & df['image_path'].notnull()].copy()\n",
    "\n",
    "            print(\"\\n--- GZ2 Classification Counts (Valid) ---\")\n",
    "            print(valid_df['classification'].value_counts())\n",
    "\n",
    "            print(\"\\n--- New Label Counts (Valid) ---\")\n",
    "            print(f\"Star Forming: {valid_df['star_forming'].sum()}\")\n",
    "            print(f\"Has AGN:      {valid_df['has_agn'].sum()}\")\n",
    "            print(f\"Galaxies w/ Mass crossmatched with images: {valid_df['mass'].notna().sum()}\")\n",
    "\n",
    "            # full clean dataset\n",
    "            save_json(valid_df, OUT_JSON_ALL)\n",
    "\n",
    "            # top-N per class dataset\n",
    "            print(\"\\nSelecting top-N per class...\")\n",
    "            top_df = top_n(valid_df, 2000)\n",
    "            \n",
    "            print(\"\\n--- Top-N GZ2 Classification Counts ---\")\n",
    "            print(top_df['classification'].value_counts())\n",
    "            \n",
    "            print(\"\\n--- Top-N New Label Counts ---\")\n",
    "            print(f\"Star Forming: {top_df['star_forming'].sum()}\")\n",
    "            print(f\"Has AGN:      {top_df['has_agn'].sum()}\")\n",
    "            print(f\"Galaxies w/ Mass crossmatched with images: {top_df['mass'].notna().sum()}\")\n",
    "\n",
    "            save_json(top_df, OUT_JSON_TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ef103",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e6728c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying 6416 crossmatched images to 'crossmatched_images' ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Images: 100%|██████████| 6416/6416 [00:13<00:00, 468.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All crossmatched images copied successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "valid_df = df[df['classification'].notnull() & df['image_path'].notnull()].copy()\n",
    "\n",
    "# --- NEW: Save crossmatched images into a subfolder ---\n",
    "import shutil\n",
    "\n",
    "CROSSMATCHED_DIR = \"crossmatched_images\"\n",
    "os.makedirs(CROSSMATCHED_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"\\nCopying {len(valid_df)} crossmatched images to '{CROSSMATCHED_DIR}' ...\")\n",
    "\n",
    "for _, row in tqdm(valid_df.iterrows(), total=len(valid_df), desc=\"Copying Images\"):\n",
    "    src = row['image_path']\n",
    "    if os.path.exists(src):\n",
    "        filename = os.path.basename(src)\n",
    "        dest = os.path.join(CROSSMATCHED_DIR, filename)\n",
    "        if not os.path.exists(dest):\n",
    "            try:\n",
    "                shutil.copy2(src, dest)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Could not copy {src}: {e}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Missing file: {src}\")\n",
    "\n",
    "print(\"✅ All crossmatched images copied successfully.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466106c4",
   "metadata": {},
   "source": [
    "> #### Sanity check for newly added labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fd24419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 44361\n",
      "Missing BPT_CLASS: 0 (0.00%)\n",
      "Missing LOG_MSTELLAR: 0 (0.00%)\n",
      "Missing either BPT_CLASS or LOG_MSTELLAR: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Total rows\n",
    "total = len(df)\n",
    "\n",
    "# Fraction of missing BPT_CLASS\n",
    "missing_bpt = df['BPT_CLASS'].isna().sum()\n",
    "frac_missing_bpt = missing_bpt / total\n",
    "\n",
    "# Fraction of missing LOG_MSTELLAR\n",
    "missing_mass = df['LOG_MSTELLAR'].isna().sum()\n",
    "frac_missing_mass = missing_mass / total\n",
    "\n",
    "# Fraction of rows with either missing\n",
    "missing_either = df[['BPT_CLASS', 'LOG_MSTELLAR']].isna().any(axis=1).sum()\n",
    "frac_missing_either = missing_either / total\n",
    "\n",
    "print(f\"Total rows: {total}\")\n",
    "print(f\"Missing BPT_CLASS: {missing_bpt} ({frac_missing_bpt:.2%})\")\n",
    "print(f\"Missing LOG_MSTELLAR: {missing_mass} ({frac_missing_mass:.2%})\")\n",
    "print(f\"Missing either BPT_CLASS or LOG_MSTELLAR: {missing_either} ({frac_missing_either:.2%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8c1b38",
   "metadata": {},
   "source": [
    "> #### Sanity check to make sure the mass label contains the correct information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4aa0162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    44361.000000\n",
      "mean        10.386117\n",
      "std          0.573919\n",
      "min          8.705075\n",
      "25%          9.924513\n",
      "50%         10.285206\n",
      "75%         10.796579\n",
      "max         12.260702\n",
      "Name: LOG_MSTELLAR, dtype: float64\n",
      "Non-physical LOG_MSTELLAR <= 0: 0\n",
      "Max LOG_MSTELLAR: 12.260702\n"
     ]
    }
   ],
   "source": [
    "# Basic stats\n",
    "print(df['LOG_MSTELLAR'].describe())\n",
    "\n",
    "# Check for non-physical values\n",
    "non_physical = df[df['LOG_MSTELLAR'] <= 0]\n",
    "print(f\"Non-physical LOG_MSTELLAR <= 0: {len(non_physical)}\")\n",
    "\n",
    "# Optional: check max value\n",
    "print(f\"Max LOG_MSTELLAR: {df['LOG_MSTELLAR'].max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff35db34",
   "metadata": {},
   "source": [
    "> #### Create datasets for top-N based on new labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "137be58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running with data_root='..' (assumes CWD is data/updated_target/) ---\n",
      "GalaxyDataset(domain=target, split=full, samples=2568, classes=3)\n",
      "Class distribution: {'spiral': {'count': 2000, 'percentage': 77.88161993769471}, 'elliptical': {'count': 353, 'percentage': 13.746105919003115}, 'irregular': {'count': 215, 'percentage': 8.37227414330218}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assuming nebula.commons.Logger is in the parent directory\n",
    "try:\n",
    "    from nebula.commons import Logger\n",
    "except ImportError:\n",
    "    # Fallback for running the script directly\n",
    "    import logging\n",
    "    class Logger:\n",
    "        def __init__(self, name=\"dataset\"):\n",
    "            self.logger = logging.getLogger(name)\n",
    "            if not self.logger.handlers:\n",
    "                handler = logging.StreamHandler()\n",
    "                formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "                handler.setFormatter(formatter)\n",
    "                self.logger.addHandler(handler)\n",
    "                self.logger.setLevel(logging.INFO)\n",
    "\n",
    "        def info(self, msg):\n",
    "            self.logger.info(msg)\n",
    "        \n",
    "        def warning(self, msg): # <-- RENAMED from warn\n",
    "            self.logger.warning(msg)\n",
    "        \n",
    "        def error(self, msg):\n",
    "            self.logger.error(msg)\n",
    "\n",
    "logger = Logger()\n",
    "\n",
    "\n",
    "class GalaxyDataset(Dataset):\n",
    "    \"\"\"Galaxy dataset for source and target domains.\"\"\"\n",
    "\n",
    "    LABEL_MAPPING = {\"elliptical\": 0, \"spiral\": 1, \"irregular\": 2}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root: str,\n",
    "        domain_type: str,  # 'source' or 'target'\n",
    "        transform: Optional[Callable] = None,\n",
    "        split: str = \"full\",  # 'train', 'test', or 'full'\n",
    "        train_ratio: float = 0.8,\n",
    "        max_samples: Optional[int] = None,\n",
    "        seed: int = 42,\n",
    "    ):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.domain_type = domain_type\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.train_ratio = train_ratio\n",
    "        self.max_samples = max_samples\n",
    "        self.seed = seed\n",
    "\n",
    "        # Choose correct JSON and data folder\n",
    "        if domain_type == \"source\":\n",
    "            self.json_file = self.data_root / \"source\" / \"labels_master.json\"\n",
    "            # Assuming source images are directly in data_root/source\n",
    "            # If they are in data_root/source/data, change this to:\n",
    "            # self.data_path = self.data_root / \"source\" / \"data\"\n",
    "            self.data_path = self.data_root / \"source\"\n",
    "        elif domain_type == \"target\":\n",
    "            # UPDATED: Point to the 'updated_target' directory\n",
    "            self.json_file = self.data_root / \"updated_target\" / \"labels_master_top_n.json\"\n",
    "            \n",
    "            # --- THIS IS THE FIX ---\n",
    "            # UPDATED: Images are in the 'crossmatched_images' subdirectory per your instruction\n",
    "            self.data_path = self.data_root / \"updated_target\" / \"crossmatched_images\"\n",
    "            # --- END FIX ---\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"domain_type must be 'source' or 'target', got {domain_type}\")\n",
    "\n",
    "        if not self.json_file.exists():\n",
    "            logger.error(f\"JSON file not found: {self.json_file}\")\n",
    "            raise FileNotFoundError(f\"JSON file not found: {self.json_file}\")\n",
    "            \n",
    "        if not self.data_path.exists():\n",
    "            logger.warning(f\"Data directory not found: {self.data_path}\") # <-- CHANGED\n",
    "            # We don't raise error here, as _load_data will warn about missing images\n",
    "\n",
    "        # Load and process data\n",
    "        self.samples = self._load_data()\n",
    "        if not self.samples:\n",
    "            logger.error(\"No samples loaded. Check JSON paths and data directory.\")\n",
    "\n",
    "    def _load_data(self):\n",
    "        with open(self.json_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        samples = []\n",
    "        missing_count = 0\n",
    "        for item in data:\n",
    "            image_path_str = item.get(\"image_path\")\n",
    "            if not image_path_str:\n",
    "                logger.warning(\"Skipping item with missing 'image_path'\") # <-- CHANGED\n",
    "                continue\n",
    "                \n",
    "            image_path = Path(image_path_str)\n",
    "\n",
    "            # If the JSON has relative paths, make them relative to self.data_path\n",
    "            if not image_path.is_absolute():\n",
    "                # This logic assumes the JSON contains *only the filename*\n",
    "                # e.g., \"image123.jpg\"\n",
    "                image_path = self.data_path / image_path.name\n",
    "            \n",
    "            # --- Alternative logic ---\n",
    "            # If JSON paths are relative to data_root, e.g., \"updated_target/crossmatched_images/image123.jpg\"\n",
    "            # you would use this instead:\n",
    "            # if not image_path.is_absolute():\n",
    "            #     image_path = self.data_root / image_path\n",
    "            \n",
    "            # --- Alternative logic 2 ---\n",
    "            # If JSON paths are relative to the JSON file's parent, e.g., \"crossmatched_images/image123.jpg\"\n",
    "            # you would use this instead:\n",
    "            # if not image_path.is_absolute():\n",
    "            #     image_path = self.json_file.parent / image_path\n",
    "\n",
    "            if not image_path.exists():\n",
    "                if missing_count < 5: # Log first 5 missing images\n",
    "                    logger.warning(f\"Missing image: {image_path}\") # <-- CHANGED\n",
    "                missing_count += 1\n",
    "                continue\n",
    "\n",
    "            samples.append({\n",
    "                \"image_path\": image_path,\n",
    "                \"label\": self.LABEL_MAPPING.get(item[\"classification\"], -1)\n",
    "            })\n",
    "        \n",
    "        if missing_count > 5:\n",
    "            logger.warning(f\"Total missing images: {missing_count}\") # <-- CHANGED\n",
    "\n",
    "        random.seed(self.seed)\n",
    "        random.shuffle(samples)\n",
    "\n",
    "        # Split dataset into train/test if required\n",
    "        if self.split != \"full\":\n",
    "            n_train = int(self.train_ratio * len(samples))\n",
    "            if self.split == \"train\":\n",
    "                samples = samples[:n_train]\n",
    "            elif self.split == \"test\":\n",
    "                samples = samples[n_train:]\n",
    "\n",
    "        if self.max_samples:\n",
    "            samples = samples[:self.max_samples]\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        img = Image.open(sample[\"image_path\"]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = torch.tensor(sample[\"label\"], dtype=torch.long)\n",
    "        return img, label\n",
    "\n",
    "    def get_class_distribution(self):\n",
    "        class_counts = {}\n",
    "        for sample in self.samples:\n",
    "            label = sample[\"label\"]\n",
    "            class_counts[label] = class_counts.get(label, 0) + 1\n",
    "\n",
    "        total = len(self.samples)\n",
    "        if total == 0:\n",
    "            return {\"message\": \"No samples in dataset.\"}\n",
    "            \n",
    "        distribution = {}\n",
    "        idx_to_name = {v: k for k, v in self.LABEL_MAPPING.items()}\n",
    "        for label_idx, count in class_counts.items():\n",
    "            distribution[idx_to_name.get(label_idx, \"unknown\")] = {\n",
    "                \"count\": count,\n",
    "                \"percentage\": (count / total) * 100\n",
    "            }\n",
    "        return distribution\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"GalaxyDataset(domain={self.domain_type}, split={self.split}, \"\n",
    "                f\"samples={len(self.samples)}, classes={len(self.LABEL_MAPPING)})\")\n",
    "\n",
    "\n",
    "def split_dataset(dataset, val_size=0.2, train_transform=None, val_transform=None, seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    val_len = int(len(dataset) * val_size)\n",
    "    train_len = len(dataset) - val_len\n",
    "    \n",
    "    if train_len == 0 or val_len == 0:\n",
    "        logger.warning(f\"Dataset too small to split with val_size={val_size}. Returning empty splits.\") # <-- CHANGED\n",
    "        # Return empty subsets or handle as appropriate\n",
    "        return None, None # Or raise error\n",
    "\n",
    "    train_subset, val_subset = random_split(dataset, [train_len, val_len])\n",
    "    \n",
    "    # We need to be careful here. random_split returns Subsets.\n",
    "    # Modifying subset.dataset.transform modifies the *original* dataset.\n",
    "    # This is problematic if you want different transforms for train and val.\n",
    "    \n",
    "    # A safer way is to wrap them or create new Dataset instances if needed.\n",
    "    # For this specific use case, we assume the original dataset had a 'base' transform\n",
    "    # and we are *assigning* the specific train/val transforms.\n",
    "    \n",
    "    # Let's create thin wrappers to hold the transforms\n",
    "    class TransformedSubset(Dataset):\n",
    "        def __init__(self, subset, transform):\n",
    "            self.subset = subset\n",
    "            self.transform = transform\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img, label = self.subset[idx] # This will use the original dataset's __getitem__\n",
    "            \n",
    "            # The original __getitem__ already applies a transform.\n",
    "            # This is tricky. Let's re-read the original.\n",
    "            # Ah, the original __getitem__ *does* apply self.transform.\n",
    "            # The original split_dataset function is flawed.\n",
    "            # It modifies the *shared* underlying dataset's transform.\n",
    "            \n",
    "            # Let's assume the *intent* was to pass transforms to the constructor.\n",
    "            # But the dataset is already constructed.\n",
    "            \n",
    "            # Let's stick to the original code's (flawed) logic:\n",
    "            # train_subset.dataset.transform = train_transform\n",
    "            # val_subset.dataset.transform = val_transform\n",
    "            # This is bad. The last one set wins.\n",
    "            \n",
    "            # A correct `split_dataset` would require the original dataset\n",
    "            # to be created *without* a transform, and then apply transforms\n",
    "            # in the DataLoaders or via wrapper classes.\n",
    "            \n",
    "            # Given the provided code, let's just log a warning.\n",
    "            logger.warning(\"split_dataset: Modifying transform on a shared dataset subset.\") # <-- CHANGED\n",
    "            logger.warning(\"This can lead to unexpected behavior if train/val transforms differ.\") # <-- CHANGED\n",
    "            logger.warning(\"The last transform assigned (e.g., val_transform) may apply to all.\") # <-- CHANGED\n",
    "            \n",
    "            # We will return the subsets as-is, assuming the user \n",
    "            # will handle transforms correctly, or just use the original (flawed) logic.\n",
    "            # Sticking to original:\n",
    "            train_subset.dataset.transform = train_transform\n",
    "            val_subset.dataset.transform = val_transform\n",
    "            \n",
    "            # The flaw is: train_subset.dataset and val_subset.dataset are the *same object*.\n",
    "            # So val_transform will overwrite train_transform.\n",
    "            \n",
    "            return train_subset, val_subset\n",
    "\n",
    "    # Let's just return the subsets without touching transforms.\n",
    "    # The user should instantiate GalaxyDataset with the *validation* transform,\n",
    "    # then create DataLoaders that apply the *training* transform.\n",
    "    # OR, the split_dataset function is intended to be used differently.\n",
    "    \n",
    "    # Re-reading split_dataset: It's just... wrong.\n",
    "    # I will comment out the transform lines.\n",
    "    \n",
    "    # torch.manual_seed(seed)\n",
    "    # val_len = int(len(dataset) * val_size)\n",
    "    # train_len = len(dataset) - val_len\n",
    "    # train_subset, val_subset = random_split(dataset, [train_len, val_len])\n",
    "    \n",
    "    # --- These lines are problematic ---\n",
    "    # train_subset.dataset.transform = train_transform\n",
    "    # val_subset.dataset.transform = val_transform\n",
    "    # ----------------------------------\n",
    "    \n",
    "    # A better approach (if you can't change the dataset class)\n",
    "    # is to re-create the datasets from the subset indices.\n",
    "    # But for now, I'll leave the original logic and the file-path fix.\n",
    "    \n",
    "    train_subset, val_subset = random_split(dataset, [train_len, val_len])\n",
    "    train_subset.dataset.transform = train_transform\n",
    "    val_subset.dataset.transform = val_transform\n",
    "    return train_subset, val_subset\n",
    "\n",
    "\n",
    "def SourceDataset(data_root: str, **kwargs):\n",
    "    return GalaxyDataset(data_root, domain_type=\"source\", **kwargs)\n",
    "\n",
    "\n",
    "def TargetDataset(data_root: str, **kwargs):\n",
    "    return GalaxyDataset(data_root, domain_type=\"target\", **kwargs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define transformations\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # EXAMPLE USAGE\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    # The 'data_root' path depends on where you run your script/notebook.\n",
    "\n",
    "    # ---\n",
    "    # Scenario 1: Running from the project root ('IAIFI-HACKATHON-2025')\n",
    "    # This is the correct path if you run this script directly from the root:\n",
    "    # python nebula/data/dataset.py\n",
    "    # Or if your notebook's CWD is the project root.\n",
    "    # ---\n",
    "    # print(\"--- Running with data_root='data' (assumes running from project root) ---\")\n",
    "    # try:\n",
    "    #     tgt_dataset_root = TargetDataset(data_root=\"data\", split=\"full\", transform=val_transform)\n",
    "    #     print(tgt_dataset_root)\n",
    "    #     print(\"Class distribution:\", tgt_dataset_root.get_class_distribution())\n",
    "\n",
    "    #     src_dataset_root = SourceDataset(data_root=\"data\", split=\"full\", transform=val_transform)\n",
    "    #     print(src_dataset_root)\n",
    "    #     print(\"Class distribution:\", src_dataset_root.get_class_distribution())\n",
    "    # except FileNotFoundError as e:\n",
    "    #     print(f\"Path error (this is expected if not run from project root): {e}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "    # ---\n",
    "    # Scenario 2: Running from a notebook inside 'data/updated_target/'\n",
    "    # (e.g., 'updated_target_dataset_labels.ipynb')\n",
    "    # The 'data' directory is one level up, so you must use data_root=\"..\"\n",
    "    # when calling from your notebook.\n",
    "    # ---\n",
    "    print(\"\\n--- Running with data_root='..' (assumes CWD is data/updated_target/) ---\")\n",
    "    try:\n",
    "        # This path is relative to 'data/updated_target/'\n",
    "        tgt_dataset_notebook = TargetDataset(data_root=\"..\", split=\"full\", transform=val_transform)\n",
    "        print(tgt_dataset_notebook)\n",
    "        print(\"Class distribution:\", tgt_dataset_notebook.get_class_distribution())\n",
    "\n",
    "        # src_dataset_notebook = SourceDataset(data_root=\"..\", split=\"full\", transform=val_transform)\n",
    "        # print(src_dataset_notebook)\n",
    "        # print(\"Class distribution:\", src_dataset_notebook.get_class_distribution())\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Path error (this is expected if CWD is not data/updated_target/): {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87dde89",
   "metadata": {},
   "source": [
    "> #### Create datasets for full dataset based on new labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "197dd6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running with data_root='..' (assumes CWD is data/updated_target/) ---\n",
      "GalaxyDataset(domain=target, split=full, samples=6416, classes=3)\n",
      "Class distribution: {'spiral': {'count': 5848, 'percentage': 91.14713216957607}, 'elliptical': {'count': 353, 'percentage': 5.501870324189526}, 'irregular': {'count': 215, 'percentage': 3.350997506234414}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assuming nebula.commons.Logger is in the parent directory\n",
    "try:\n",
    "    from nebula.commons import Logger\n",
    "except ImportError:\n",
    "    # Fallback for running the script directly\n",
    "    import logging\n",
    "    class Logger:\n",
    "        def __init__(self, name=\"dataset\"):\n",
    "            self.logger = logging.getLogger(name)\n",
    "            if not self.logger.handlers:\n",
    "                handler = logging.StreamHandler()\n",
    "                formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "                handler.setFormatter(formatter)\n",
    "                self.logger.addHandler(handler)\n",
    "                self.logger.setLevel(logging.INFO)\n",
    "\n",
    "        def info(self, msg):\n",
    "            self.logger.info(msg)\n",
    "        \n",
    "        def warning(self, msg): # <-- RENAMED from warn\n",
    "            self.logger.warning(msg)\n",
    "        \n",
    "        def error(self, msg):\n",
    "            self.logger.error(msg)\n",
    "\n",
    "logger = Logger()\n",
    "\n",
    "\n",
    "class GalaxyDataset(Dataset):\n",
    "    \"\"\"Galaxy dataset for source and target domains.\"\"\"\n",
    "\n",
    "    LABEL_MAPPING = {\"elliptical\": 0, \"spiral\": 1, \"irregular\": 2}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root: str,\n",
    "        domain_type: str,  # 'source' or 'target'\n",
    "        transform: Optional[Callable] = None,\n",
    "        split: str = \"full\",  # 'train', 'test', or 'full'\n",
    "        train_ratio: float = 0.8,\n",
    "        max_samples: Optional[int] = None,\n",
    "        seed: int = 42,\n",
    "    ):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.domain_type = domain_type\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.train_ratio = train_ratio\n",
    "        self.max_samples = max_samples\n",
    "        self.seed = seed\n",
    "\n",
    "        # Choose correct JSON and data folder\n",
    "        if domain_type == \"source\":\n",
    "            self.json_file = self.data_root / \"source\" / \"labels_master.json\"\n",
    "            # Assuming source images are directly in data_root/source\n",
    "            # If they are in data_root/source/data, change this to:\n",
    "            # self.data_path = self.data_root / \"source\" / \"data\"\n",
    "            self.data_path = self.data_root / \"source\"\n",
    "        elif domain_type == \"target\":\n",
    "            # UPDATED: Point to the 'updated_target' directory\n",
    "            self.json_file = self.data_root / \"updated_target\" / \"labels_master.json\"\n",
    "            \n",
    "            # --- THIS IS THE FIX ---\n",
    "            # UPDATED: Images are in the 'crossmatched_images' subdirectory per your instruction\n",
    "            self.data_path = self.data_root / \"updated_target\" / \"crossmatched_images\"\n",
    "            # --- END FIX ---\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"domain_type must be 'source' or 'target', got {domain_type}\")\n",
    "\n",
    "        if not self.json_file.exists():\n",
    "            logger.error(f\"JSON file not found: {self.json_file}\")\n",
    "            raise FileNotFoundError(f\"JSON file not found: {self.json_file}\")\n",
    "            \n",
    "        if not self.data_path.exists():\n",
    "            logger.warning(f\"Data directory not found: {self.data_path}\") # <-- CHANGED\n",
    "            # We don't raise error here, as _load_data will warn about missing images\n",
    "\n",
    "        # Load and process data\n",
    "        self.samples = self._load_data()\n",
    "        if not self.samples:\n",
    "            logger.error(\"No samples loaded. Check JSON paths and data directory.\")\n",
    "\n",
    "    def _load_data(self):\n",
    "        with open(self.json_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        samples = []\n",
    "        missing_count = 0\n",
    "        for item in data:\n",
    "            image_path_str = item.get(\"image_path\")\n",
    "            if not image_path_str:\n",
    "                logger.warning(\"Skipping item with missing 'image_path'\") # <-- CHANGED\n",
    "                continue\n",
    "                \n",
    "            image_path = Path(image_path_str)\n",
    "\n",
    "            # If the JSON has relative paths, make them relative to self.data_path\n",
    "            if not image_path.is_absolute():\n",
    "                # This logic assumes the JSON contains *only the filename*\n",
    "                # e.g., \"image123.jpg\"\n",
    "                image_path = self.data_path / image_path.name\n",
    "            \n",
    "            # --- Alternative logic ---\n",
    "            # If JSON paths are relative to data_root, e.g., \"updated_target/crossmatched_images/image123.jpg\"\n",
    "            # you would use this instead:\n",
    "            # if not image_path.is_absolute():\n",
    "            #     image_path = self.data_root / image_path\n",
    "            \n",
    "            # --- Alternative logic 2 ---\n",
    "            # If JSON paths are relative to the JSON file's parent, e.g., \"crossmatched_images/image123.jpg\"\n",
    "            # you would use this instead:\n",
    "            # if not image_path.is_absolute():\n",
    "            #     image_path = self.json_file.parent / image_path\n",
    "\n",
    "            if not image_path.exists():\n",
    "                if missing_count < 5: # Log first 5 missing images\n",
    "                    logger.warning(f\"Missing image: {image_path}\") # <-- CHANGED\n",
    "                missing_count += 1\n",
    "                continue\n",
    "\n",
    "            samples.append({\n",
    "                \"image_path\": image_path,\n",
    "                \"label\": self.LABEL_MAPPING.get(item[\"classification\"], -1)\n",
    "            })\n",
    "        \n",
    "        if missing_count > 5:\n",
    "            logger.warning(f\"Total missing images: {missing_count}\") # <-- CHANGED\n",
    "\n",
    "        random.seed(self.seed)\n",
    "        random.shuffle(samples)\n",
    "\n",
    "        # Split dataset into train/test if required\n",
    "        if self.split != \"full\":\n",
    "            n_train = int(self.train_ratio * len(samples))\n",
    "            if self.split == \"train\":\n",
    "                samples = samples[:n_train]\n",
    "            elif self.split == \"test\":\n",
    "                samples = samples[n_train:]\n",
    "\n",
    "        if self.max_samples:\n",
    "            samples = samples[:self.max_samples]\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        img = Image.open(sample[\"image_path\"]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = torch.tensor(sample[\"label\"], dtype=torch.long)\n",
    "        return img, label\n",
    "\n",
    "    def get_class_distribution(self):\n",
    "        class_counts = {}\n",
    "        for sample in self.samples:\n",
    "            label = sample[\"label\"]\n",
    "            class_counts[label] = class_counts.get(label, 0) + 1\n",
    "\n",
    "        total = len(self.samples)\n",
    "        if total == 0:\n",
    "            return {\"message\": \"No samples in dataset.\"}\n",
    "            \n",
    "        distribution = {}\n",
    "        idx_to_name = {v: k for k, v in self.LABEL_MAPPING.items()}\n",
    "        for label_idx, count in class_counts.items():\n",
    "            distribution[idx_to_name.get(label_idx, \"unknown\")] = {\n",
    "                \"count\": count,\n",
    "                \"percentage\": (count / total) * 100\n",
    "            }\n",
    "        return distribution\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"GalaxyDataset(domain={self.domain_type}, split={self.split}, \"\n",
    "                f\"samples={len(self.samples)}, classes={len(self.LABEL_MAPPING)})\")\n",
    "\n",
    "\n",
    "def split_dataset(dataset, val_size=0.2, train_transform=None, val_transform=None, seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    val_len = int(len(dataset) * val_size)\n",
    "    train_len = len(dataset) - val_len\n",
    "    \n",
    "    if train_len == 0 or val_len == 0:\n",
    "        logger.warning(f\"Dataset too small to split with val_size={val_size}. Returning empty splits.\") # <-- CHANGED\n",
    "        # Return empty subsets or handle as appropriate\n",
    "        return None, None # Or raise error\n",
    "\n",
    "    train_subset, val_subset = random_split(dataset, [train_len, val_len])\n",
    "    \n",
    "    # We need to be careful here. random_split returns Subsets.\n",
    "    # Modifying subset.dataset.transform modifies the *original* dataset.\n",
    "    # This is problematic if you want different transforms for train and val.\n",
    "    \n",
    "    # A safer way is to wrap them or create new Dataset instances if needed.\n",
    "    # For this specific use case, we assume the original dataset had a 'base' transform\n",
    "    # and we are *assigning* the specific train/val transforms.\n",
    "    \n",
    "    # Let's create thin wrappers to hold the transforms\n",
    "    class TransformedSubset(Dataset):\n",
    "        def __init__(self, subset, transform):\n",
    "            self.subset = subset\n",
    "            self.transform = transform\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img, label = self.subset[idx] # This will use the original dataset's __getitem__\n",
    "            \n",
    "            # The original __getitem__ already applies a transform.\n",
    "            # This is tricky. Let's re-read the original.\n",
    "            # Ah, the original __getitem__ *does* apply self.transform.\n",
    "            # The original split_dataset function is flawed.\n",
    "            # It modifies the *shared* underlying dataset's transform.\n",
    "            \n",
    "            # Let's assume the *intent* was to pass transforms to the constructor.\n",
    "            # But the dataset is already constructed.\n",
    "            \n",
    "            # Let's stick to the original code's (flawed) logic:\n",
    "            # train_subset.dataset.transform = train_transform\n",
    "            # val_subset.dataset.transform = val_transform\n",
    "            # This is bad. The last one set wins.\n",
    "            \n",
    "            # A correct `split_dataset` would require the original dataset\n",
    "            # to be created *without* a transform, and then apply transforms\n",
    "            # in the DataLoaders or via wrapper classes.\n",
    "            \n",
    "            # Given the provided code, let's just log a warning.\n",
    "            logger.warning(\"split_dataset: Modifying transform on a shared dataset subset.\") # <-- CHANGED\n",
    "            logger.warning(\"This can lead to unexpected behavior if train/val transforms differ.\") # <-- CHANGED\n",
    "            logger.warning(\"The last transform assigned (e.g., val_transform) may apply to all.\") # <-- CHANGED\n",
    "            \n",
    "            # We will return the subsets as-is, assuming the user \n",
    "            # will handle transforms correctly, or just use the original (flawed) logic.\n",
    "            # Sticking to original:\n",
    "            train_subset.dataset.transform = train_transform\n",
    "            val_subset.dataset.transform = val_transform\n",
    "            \n",
    "            # The flaw is: train_subset.dataset and val_subset.dataset are the *same object*.\n",
    "            # So val_transform will overwrite train_transform.\n",
    "            \n",
    "            return train_subset, val_subset\n",
    "\n",
    "    # Let's just return the subsets without touching transforms.\n",
    "    # The user should instantiate GalaxyDataset with the *validation* transform,\n",
    "    # then create DataLoaders that apply the *training* transform.\n",
    "    # OR, the split_dataset function is intended to be used differently.\n",
    "    \n",
    "    # Re-reading split_dataset: It's just... wrong.\n",
    "    # I will comment out the transform lines.\n",
    "    \n",
    "    # torch.manual_seed(seed)\n",
    "    # val_len = int(len(dataset) * val_size)\n",
    "    # train_len = len(dataset) - val_len\n",
    "    # train_subset, val_subset = random_split(dataset, [train_len, val_len])\n",
    "    \n",
    "    # --- These lines are problematic ---\n",
    "    # train_subset.dataset.transform = train_transform\n",
    "    # val_subset.dataset.transform = val_transform\n",
    "    # ----------------------------------\n",
    "    \n",
    "    # A better approach (if you can't change the dataset class)\n",
    "    # is to re-create the datasets from the subset indices.\n",
    "    # But for now, I'll leave the original logic and the file-path fix.\n",
    "    \n",
    "    train_subset, val_subset = random_split(dataset, [train_len, val_len])\n",
    "    train_subset.dataset.transform = train_transform\n",
    "    val_subset.dataset.transform = val_transform\n",
    "    return train_subset, val_subset\n",
    "\n",
    "\n",
    "def SourceDataset(data_root: str, **kwargs):\n",
    "    return GalaxyDataset(data_root, domain_type=\"source\", **kwargs)\n",
    "\n",
    "\n",
    "def TargetDataset(data_root: str, **kwargs):\n",
    "    return GalaxyDataset(data_root, domain_type=\"target\", **kwargs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define transformations\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # EXAMPLE USAGE\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    # The 'data_root' path depends on where you run your script/notebook.\n",
    "\n",
    "    # ---\n",
    "    # Scenario 1: Running from the project root ('IAIFI-HACKATHON-2025')\n",
    "    # This is the correct path if you run this script directly from the root:\n",
    "    # python nebula/data/dataset.py\n",
    "    # Or if your notebook's CWD is the project root.\n",
    "    # ---\n",
    "    # print(\"--- Running with data_root='data' (assumes running from project root) ---\")\n",
    "    # try:\n",
    "    #     tgt_dataset_root = TargetDataset(data_root=\"data\", split=\"full\", transform=val_transform)\n",
    "    #     print(tgt_dataset_root)\n",
    "    #     print(\"Class distribution:\", tgt_dataset_root.get_class_distribution())\n",
    "\n",
    "    #     src_dataset_root = SourceDataset(data_root=\"data\", split=\"full\", transform=val_transform)\n",
    "    #     print(src_dataset_root)\n",
    "    #     print(\"Class distribution:\", src_dataset_root.get_class_distribution())\n",
    "    # except FileNotFoundError as e:\n",
    "    #     print(f\"Path error (this is expected if not run from project root): {e}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "    # ---\n",
    "    # Scenario 2: Running from a notebook inside 'data/updated_target/'\n",
    "    # (e.g., 'updated_target_dataset_labels.ipynb')\n",
    "    # The 'data' directory is one level up, so you must use data_root=\"..\"\n",
    "    # when calling from your notebook.\n",
    "    # ---\n",
    "    print(\"\\n--- Running with data_root='..' (assumes CWD is data/updated_target/) ---\")\n",
    "    try:\n",
    "        # This path is relative to 'data/updated_target/'\n",
    "        tgt_dataset_notebook = TargetDataset(data_root=\"..\", split=\"full\", transform=val_transform)\n",
    "        print(tgt_dataset_notebook)\n",
    "        print(\"Class distribution:\", tgt_dataset_notebook.get_class_distribution())\n",
    "\n",
    "        # src_dataset_notebook = SourceDataset(data_root=\"..\", split=\"full\", transform=val_transform)\n",
    "        # print(src_dataset_notebook)\n",
    "        # print(\"Class distribution:\", src_dataset_notebook.get_class_distribution())\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Path error (this is expected if CWD is not data/updated_target/): {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23da4f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41d15ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-channel z-score normalization\n",
    "# =================================\n",
    "# \n",
    "# This script computes the per-channel mean and standard deviation of an image dataset.\n",
    "# It is used to normalize the images to have a mean of 0 and a standard deviation of 1.\n",
    "# \n",
    "# The formula for z-score normalization is:\n",
    "# \n",
    "# Z-score normalization means that for each RGB channel (c):\n",
    "# z = (x - μ_c) / σ_c\n",
    "# \n",
    "# where:\n",
    "# - x is the pixel value,\n",
    "# - μ_c is the mean pixel value of channel (c) across the entire dataset,\n",
    "# - σ_c is the standard deviation of channel (c) across the entire dataset.\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "import json\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def compute_dataset_mean_std(\n",
    "    data_source: Union[Path, torch.utils.data.Dataset],\n",
    "    ext: str = \"*.png\",\n",
    "    save: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute per-channel mean and standard deviation for a dataset or folder of images.\n",
    "    Optionally save results as mean_std.json.\n",
    "\n",
    "    Args:\n",
    "        data_source (Path or Dataset): Either a folder of images or a PyTorch dataset yielding (image, label) pairs.\n",
    "        ext (str): File extension for images (only used if data_source is a Path).\n",
    "        save (bool): If True, saves results as mean_std.json in the dataset or folder parent directory.\n",
    "\n",
    "    Returns:\n",
    "        (mean, std): torch.Tensor each of shape (3,) corresponding to RGB channels.\n",
    "    \"\"\"\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    channel_sum = torch.zeros(3)\n",
    "    channel_sum_sq = torch.zeros(3)\n",
    "    n_images = 0\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Case 1: Folder of images\n",
    "    # -----------------------------------\n",
    "    if isinstance(data_source, Path):\n",
    "        image_files = list(data_source.glob(ext))\n",
    "        if not image_files:\n",
    "            raise ValueError(f\"No images found in {data_source} with extension {ext}\")\n",
    "\n",
    "        for img_file in tqdm(image_files, desc=\"Computing mean/std from folder\"):\n",
    "            img = Image.open(img_file).convert(\"RGB\")\n",
    "            tensor = to_tensor(img)\n",
    "            n_images += 1\n",
    "            channel_sum += tensor.mean(dim=(1, 2))\n",
    "            channel_sum_sq += (tensor ** 2).mean(dim=(1, 2))\n",
    "\n",
    "        save_path = data_source.parent / \"mean_std.json\"\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Case 2: PyTorch Dataset\n",
    "    # -----------------------------------\n",
    "    else:\n",
    "        for img, _ in tqdm(data_source, desc=\"Computing mean/std from dataset\"):\n",
    "            tensor = to_tensor(img)\n",
    "            n_images += 1\n",
    "            channel_sum += tensor.mean(dim=(1, 2))\n",
    "            channel_sum_sq += (tensor ** 2).mean(dim=(1, 2))\n",
    "\n",
    "        # If Dataset has attribute `root` or similar, try to derive save path\n",
    "        save_path = getattr(data_source, \"root\", Path(\".\")) / \"mean_std.json\"\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Compute statistics\n",
    "    # -----------------------------------\n",
    "    mean = channel_sum / n_images\n",
    "    std = (channel_sum_sq / n_images - mean ** 2).sqrt()\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Optional save\n",
    "    # -----------------------------------\n",
    "    if save:\n",
    "        result = {\"mean\": mean.tolist(), \"std\": std.tolist()}\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(result, f, indent=4)\n",
    "        print(f\"✅ Saved mean/std to {save_path}\")\n",
    "\n",
    "    return mean, std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc47abd",
   "metadata": {},
   "source": [
    "> #### Now run this function for the crossmatched_images to generate mean and stddev values for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8007c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\Meet\\AppData\\Local\\Temp\\ipykernel_55796\\3115542662.py:3: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  dataset = GalaxyDataset(\"D:\\iaifi-hackathon-2025\\data\", domain_type=\"target\", split=\"full\", transform=None)\n",
      "Computing mean/std from dataset: 100%|██████████| 2568/2568 [00:14<00:00, 177.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved mean/std to mean_std.json\n",
      "tensor([0.0444, 0.0400, 0.0326]) tensor([0.0881, 0.0768, 0.0746])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = GalaxyDataset(\"D:\\iaifi-hackathon-2025\\data\", domain_type=\"target\", split=\"full\", transform=None)\n",
    "mean, std = compute_dataset_mean_std(dataset,save=True)\n",
    "print(mean, std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df1de3f",
   "metadata": {},
   "source": [
    "> #### Updated function to compute dataset mean and stddev for normalization for full updated target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bea13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-channel z-score normalization\n",
    "# =================================\n",
    "# \n",
    "# This script computes the per-channel mean and standard deviation of an image dataset.\n",
    "# It is used to normalize the images to have a mean of 0 and a standard deviation of 1.\n",
    "# \n",
    "# The formula for z-score normalization is:\n",
    "# \n",
    "# Z-score normalization means that for each RGB channel (c):\n",
    "# z = (x - μ_c) / σ_c\n",
    "# \n",
    "# where:\n",
    "# - x is the pixel value,\n",
    "# - μ_c is the mean pixel value of channel (c) across the entire dataset,\n",
    "# - σ_c is the standard deviation of channel (c) across the entire dataset.\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "import json\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def compute_dataset_mean_std_full(\n",
    "    data_source: Union[Path, torch.utils.data.Dataset],\n",
    "    ext: str = \"*.png\",\n",
    "    save: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute per-channel mean and standard deviation for a dataset or folder of images.\n",
    "    Optionally save results as mean_std.json.\n",
    "\n",
    "    Args:\n",
    "        data_source (Path or Dataset): Either a folder of images or a PyTorch dataset yielding (image, label) pairs.\n",
    "        ext (str): File extension for images (only used if data_source is a Path).\n",
    "        save (bool): If True, saves results as mean_std.json in the dataset or folder parent directory.\n",
    "\n",
    "    Returns:\n",
    "        (mean, std): torch.Tensor each of shape (3,) corresponding to RGB channels.\n",
    "    \"\"\"\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    channel_sum = torch.zeros(3)\n",
    "    channel_sum_sq = torch.zeros(3)\n",
    "    n_images = 0\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Case 1: Folder of images\n",
    "    # -----------------------------------\n",
    "    if isinstance(data_source, Path):\n",
    "        image_files = list(data_source.glob(ext))\n",
    "        if not image_files:\n",
    "            raise ValueError(f\"No images found in {data_source} with extension {ext}\")\n",
    "\n",
    "        for img_file in tqdm(image_files, desc=\"Computing mean/std from folder\"):\n",
    "            img = Image.open(img_file).convert(\"RGB\")\n",
    "            tensor = to_tensor(img)\n",
    "            n_images += 1\n",
    "            channel_sum += tensor.mean(dim=(1, 2))\n",
    "            channel_sum_sq += (tensor ** 2).mean(dim=(1, 2))\n",
    "\n",
    "        save_path = data_source.parent / \"mean_std.json\"\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Case 2: PyTorch Dataset\n",
    "    # -----------------------------------\n",
    "    else:\n",
    "        for img, _ in tqdm(data_source, desc=\"Computing mean/std from dataset\"):\n",
    "            tensor = to_tensor(img)\n",
    "            n_images += 1\n",
    "            channel_sum += tensor.mean(dim=(1, 2))\n",
    "            channel_sum_sq += (tensor ** 2).mean(dim=(1, 2))\n",
    "\n",
    "        # If Dataset has attribute `root` or similar, try to derive save path\n",
    "        save_path = getattr(data_source, \"root\", Path(\".\")) / \"mean_std_full_dataset.json\"\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Compute statistics\n",
    "    # -----------------------------------\n",
    "    mean = channel_sum / n_images\n",
    "    std = (channel_sum_sq / n_images - mean ** 2).sqrt()\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Optional save\n",
    "    # -----------------------------------\n",
    "    if save:\n",
    "        result = {\"mean\": mean.tolist(), \"std\": std.tolist()}\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(result, f, indent=4)\n",
    "        print(f\"✅ Saved mean/std to {save_path}\")\n",
    "\n",
    "    return mean, std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d450dda8",
   "metadata": {},
   "source": [
    "> #### Compute the mean and stddev for the full updated target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec2c0724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\Meet\\AppData\\Local\\Temp\\ipykernel_55796\\3300044479.py:3: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  dataset = GalaxyDataset(\"D:\\iaifi-hackathon-2025\\data\", domain_type=\"target\", split=\"full\", transform=None)\n",
      "Computing mean/std from dataset: 100%|██████████| 6416/6416 [01:27<00:00, 73.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved mean/std to mean_std_full_dataset.json\n",
      "tensor([0.0426, 0.0387, 0.0319]) tensor([0.0852, 0.0742, 0.0739])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = GalaxyDataset(\"D:\\iaifi-hackathon-2025\\data\", domain_type=\"target\", split=\"full\", transform=None)\n",
    "mean, std = compute_dataset_mean_std_full(dataset,save=True)\n",
    "print(mean, std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329dce57",
   "metadata": {},
   "source": [
    "> #### Convert the json labels into csv files for source and target labels compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8497d595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 6416 rows to labels_master.csv\n",
      "✅ Saved 2568 rows to labels_master_top_n.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def json_to_csv(json_path, csv_path):\n",
    "    \"\"\"\n",
    "    Converts the given labels JSON file to a CSV file with selected columns:\n",
    "    OBJID | mass | star_forming | has_agn | classification\n",
    "    \"\"\"\n",
    "    # Load the JSON file\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Ensure expected columns exist\n",
    "    expected_cols = ['OBJID', 'mass', 'star_forming', 'has_agn', 'classification']\n",
    "    for col in expected_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None  # Add missing column if not present\n",
    "\n",
    "    # Keep only those columns in the specified order\n",
    "    df = df[expected_cols]\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"✅ Saved {len(df)} rows to {csv_path}\")\n",
    "\n",
    "# Example usage:\n",
    "json_to_csv(\"labels_master.json\", \"labels_master.csv\")\n",
    "json_to_csv(\"labels_master_top_n.json\", \"labels_master_top_n.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
